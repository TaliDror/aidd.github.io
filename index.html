<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Token-Based Audio Inpainting via Discrete Diffusion</title>

  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
      margin: 0;
      padding: 0;
      background: #ffffff;
      color: #111;
      line-height: 1.6;
    }

    .container {
      max-width: 900px;
      margin: 0 auto;
      padding: 40px 20px 80px;
    }

    h1 {
      text-align: center;
      font-size: 2.4em;
      margin-bottom: 0.4em;
    }

    h2 {
      margin-top: 2.2em;
      border-bottom: 1px solid #eaeaea;
      padding-bottom: 0.3em;
    }

    .authors {
      text-align: center;
      font-size: 1.05em;
      margin-bottom: 0.3em;
    }

    .affiliations {
      text-align: center;
      color: #555;
      font-size: 0.95em;
      margin-bottom: 1em;
    }

    .links {
      text-align: center;
      margin: 1.2em 0 2em;
    }

    .links a {
      margin: 0 10px;
      padding: 8px 14px;
      border: 1px solid #ddd;
      border-radius: 6px;
      text-decoration: none;
      color: #111;
      font-size: 0.95em;
    }

    .links a:hover {
      background: #f5f5f5;
    }

    .figure {
      text-align: center;
      margin: 2.5em 0;
    }

    .figure img {
      max-width: 100%;
      border-radius: 6px;
    }

    .caption {
      font-size: 0.9em;
      color: #555;
      margin-top: 0.6em;
    }

    .abstract {
      background: #fafafa;
      border: 1px solid #eaeaea;
      border-radius: 8px;
      padding: 20px;
    }

    pre {
      background: #f6f8fa;
      padding: 15px;
      border-radius: 6px;
      overflow-x: auto;
      font-size: 0.9em;
    }

    footer {
      margin-top: 4em;
      text-align: center;
      color: #777;
      font-size: 0.85em;
    }
  </style>
</head>

<body>
  <div class="container">

    <h1>Token-Based Audio Inpainting via Discrete Diffusion</h1>

    <div class="authors">
      Tali Dror<sup>*</sup>, Iftach Shoham<sup>*</sup>, Moshe Buchris,
      Oren Gal, Haim Permuter, Gilad Katz, Eliya Nachmani
    </div>

    <div class="affiliations">
      Ben-Gurion University of the Negev Â· University of Haifa<br>
      <sup>*</sup>Equal contribution
    </div>

    <div class="links">
      <a href="https://arxiv.org/abs/2507.08333" target="_blank">ðŸ“„ Paper (arXiv)</a>
      <a href="https://github.com/iftachShoham/AIDD" target="_blank">ðŸ’» Code</a>
      <a href="https://huggingface.co/TaliDror/AIDD" target="_blank">ðŸ¤— Model Weights</a>
    </div>

    <div class="figure">
      <img src="method_figure.png" alt="AIDD overview">
      <div class="caption">
        Overview of AIDD. Audio is tokenized using WavTokenizer, inpainted via discrete diffusion,
        and decoded back to waveform audio.
      </div>
    </div>

    <h2>Abstract</h2>
    <div class="abstract">
      Audio inpainting seeks to restore missing segments in degraded recordings. Previous
      diffusion-based methods exhibit impaired performance when the missing region is large.
      We introduce the first approach that applies discrete diffusion over tokenized music
      representations, enabling stable and semantically coherent restoration of long gaps.
      Our method incorporates span-based masking and a derivative-based regularization loss,
      and achieves state-of-the-art performance on MusicNet and MAESTRO for gaps up to 750 ms.
    </div>

    <h2>Method</h2>
    <p>
      AIDD operates entirely in a discrete token space. Raw audio waveforms are first converted
      into compact sequences of discrete tokens using a pretrained <b>WavTokenizer</b>.
      A <b>Diffusion Transformer (DiT)</b> then performs inpainting by learning the reverse
      discrete diffusion process with an absorbing mask state.
    </p>
    <p>
      To better model structured missing regions, we introduce <b>span-based masking</b> during
      training. Additionally, a <b>derivative-based regularization loss</b> encourages smooth
      temporal dynamics in token embedding space, improving perceptual coherence of the
      reconstructed audio.
    </p>

<h2>Results</h2>
<p>
  AIDD achieves competitive or state-of-the-art results on MusicNet and MAESTRO across
  objective metrics (FAD, LSD, ODG) and subjective MOS evaluations, particularly for
  medium and long gaps (150â€“750 ms), while being more efficient than prior diffusion-based
  approaches.
</p>

<!-- ================= AUDIO EXAMPLES ================= -->

<h2 style="text-align:center; margin-top:3rem;">Audio Examples</h2>

<p style="text-align:center;">
Qualitative examples from MAESTRO with 375 ms and 750 ms gaps.
Each row shows Original, Masked, and AIDD Reconstruction.
</p>

<!-- 375 ms -->
<h3>Gap: 375 ms</h3>

<table style="width:100%; text-align:center; margin-bottom:2rem;">
<tr>
  <th>Original</th>
  <th>Masked</th>
  <th>AIDD</th>
</tr>
<tr>
  <td>
    <audio controls>
      <source src="AIDD%20-%20audio%20examples/375/original/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--4.wav" type="audio/wav">
    </audio>
  </td>
  <td>
    <audio controls>
      <source src="AIDD%20-%20audio%20examples/375/masked/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--4.wav" type="audio/wav">
    </audio>
  </td>
  <td>
    <audio controls>
      <source src="AIDD%20-%20audio%20examples/375/reconstructed/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--4.wav" type="audio/wav">
    </audio>
  </td>
</tr>
</table>

<!-- 750 ms -->
<h3>Gap: 750 ms</h3>

<table style="width:100%; text-align:center; margin-bottom:2rem;">
<tr>
  <th>Original</th>
  <th>Masked</th>
  <th>AIDD</th>
</tr>
<tr>
  <td>
    <audio controls>
      <source src="AIDD%20-%20audio%20examples/750/original/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--4.wav" type="audio/wav">
    </audio>
  </td>
  <td>
    <audio controls>
      <source src="AIDD%20-%20audio%20examples/750/masked/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--4.wav" type="audio/wav">
    </audio>
  </td>
  <td>
    <audio controls>
      <source src="AIDD%20-%20audio%20examples/750/reconstructed/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--4.wav" type="audio/wav">
    </audio>
  </td>
</tr>
</table>

<h2>Citation</h2>

    <pre>
@article{dror2025token,
  title={Token-based Audio Inpainting via Discrete Diffusion},
  author={Dror, Tali and Shoham, Iftach and Buchris, Moshe and Gal, Oren and Permuter, Haim and Katz, Gilad and Nachmani, Eliya},
  journal={arXiv preprint arXiv:2507.08333},
  year={2025}
}
    </pre>

    <h2>Acknowledgments</h2>
    <p>
      This work is built upon prior works, including
      <i>Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution</i>
      and <i>WavTokenizer: An Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling</i>.
      We are grateful to the authors for making their methods and code publicly available.
    </p>



  </div>
</body>
</html>
